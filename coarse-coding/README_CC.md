Square Wave Function Approximation â€“ Feature-Based Value Estimation
Overview

This project demonstrates feature-based value function approximation, a core concept used in reinforcement learning and function estimation for representing continuous or complex state spaces.
It approximates a discontinuous square wave using overlapping feature intervals and online gradient descent.

How It Works

Target function:

ğ‘“
(
ğ‘¥
)
=
1
f(x)=1 if 
0.5
<
ğ‘¥
<
1.5
0.5<x<1.5; 
ğ‘“
(
ğ‘¥
)
=
0
f(x)=0 otherwise
Domain: [0, 2)

Approximation model:
The domain is divided into overlapping feature windows.
Each active feature contributes a weight 
ğ‘¤
ğ‘–
w
i
	â€‹

:

ğ‘£
^
(
ğ‘¥
)
=
âˆ‘
ğ‘–
âˆˆ
ğ‘
ğ‘
ğ‘¡
ğ‘–
ğ‘£
ğ‘’
(
ğ‘¥
)
ğ‘¤
ğ‘–
v
^
(x)=
iâˆˆactive(x)
âˆ‘
	â€‹

w
i
	â€‹


Learning rule:

ğ‘¤
ğ‘–
â†
ğ‘¤
ğ‘–
+
ğ›¼
â‹…
(
ğ‘“
(
ğ‘¥
)
âˆ’
ğ‘£
^
(
ğ‘¥
)
)
/
ğ‘›
ğ‘
ğ‘
ğ‘¡
ğ‘–
ğ‘£
ğ‘’
w
i
	â€‹

â†w
i
	â€‹

+Î±â‹…(f(x)âˆ’
v
^
(x))/n
active
	â€‹


where Î± is the learning rate and n_active is the number of active features.

Parameters
Parameter	Description	Default
feature_width	Width of each feature window	0.1
step_size	Learning rate	0.2
num_of_features	Number of overlapping features	50
domain	Input space	[0.0, 2.0]
Files

square_wave.py â€“ Main training script

classes.py â€“ Defines Interval and ValueFunction classes

square_wave.ipynb â€“ Notebook for visualization and experiments

requirements.txt â€“ Project dependencies

Results

The model learns to approximate the square wave by adjusting weights of active features.
Overlapping intervals allow smooth approximation even near discontinuities.

Applications

Value function estimation in Reinforcement Learning

Continuous state approximation

Simple online learning demonstration