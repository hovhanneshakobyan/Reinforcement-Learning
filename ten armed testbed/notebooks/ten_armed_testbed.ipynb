{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 10-armed Testbed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cada6500ddd403c4"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T11:30:02.894999Z",
     "start_time": "2025-03-10T11:30:02.091555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import sys\n",
    "\n",
    "# sys.path.append(r\"C:\\Users\\asus\\Desktop\\ReinforcementLearning\\ten-armed-testbed\")\n",
    "# sys.path.append(r\"C:\\Users\\asus\\Desktop\\ReinforcementLearning\\ten-armed-testbed\")\n",
    "from src.bandit import Bandit\n",
    "# from src.bandit import Bandit\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# f = Bandit()\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "duplicate argument 'use_gradient' in function definition (bandit.py, line 9)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[1;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[0;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3579\u001B[0m in \u001B[0;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 9\u001B[1;36m\n\u001B[1;33m    from src.bandit import Bandit\u001B[1;36m\n",
      "\u001B[1;36m  File \u001B[1;32m~\\Desktop\\ReinforcementLearning\\ten-armed-testbed\\src\\bandit.py:9\u001B[1;36m\u001B[0m\n\u001B[1;33m    use_gradient: bool = False, step_size=0.1, use_gradient_baseline: bool = False, true_expected_reward=0.):\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m duplicate argument 'use_gradient' in function definition\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T10:08:01.762620Z",
     "start_time": "2025-03-10T10:08:01.754689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def simulate(runs, times, bandits):\n",
    "    # region Summary\n",
    "    \"\"\"\n",
    "    For any learning method, we can measure its performance and behavior as it improves with experience over 1000 time steps\n",
    "    when applied to 1 of the bandit problems. This makes up 1 run. Repeating this for 2000 independent runs, each with a different\n",
    "    bandit problem, we obtained measures of the learning algorithm‚Äôs average behavior.\n",
    "    :param runs: Number of runs\n",
    "    :param times: Number of times\n",
    "    :param bandits: Bandit problems\n",
    "    :return: Optimal action count mean and reward mean\n",
    "    \"\"\"\n",
    "    # endregion Summary\n",
    "\n",
    "    # region Body\n",
    "\n",
    "    # Prepare a matrix filled with 0s for rewards\n",
    "    rewards = np.zeros((len(bandits),runs, times))\n",
    "\n",
    "    # Prepare a matrix filled with 0s for optimal action counts that has the same shape as rewards matrix\n",
    "    optimal_action_counts = np.zeros(rewards.shape)\n",
    "\n",
    "    # For every bandit\n",
    "    for i, bandit in enumerate(bandits):\n",
    "        # for every run\n",
    "        for run in trange(runs):\n",
    "            # initialize bandit\n",
    "            bandit.initialize()\n",
    "\n",
    "            # for every time step\n",
    "            for time in range(times):\n",
    "                # select an action\n",
    "                action = bandit.act()\n",
    "\n",
    "                # get the reward\n",
    "                rewards[i, run, time] = bandit.step(action)\n",
    "\n",
    "                # if the selected action is optimal for bandit\n",
    "                if action == bandit.optimal_action:\n",
    "\n",
    "                    # change the corresponding 0 in the optimal action counts matrix to 1\n",
    "                    optimal_action_counts[i, run, time] = 1\n",
    "\n",
    "    return  optimal_action_counts.mean(axis=1), rewards.mean(axis = 1)\n",
    "\n",
    "    # endregion Body"
   ],
   "id": "be09fd89ebd40d84",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Reward Distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4088366f60e51478"
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot an example reward distribution\n",
    "plt.violinplot(dataset=np.random.randn(200, 10) + np.random.randn(10))\n",
    "plt.title(\"Figure 2.1\")\n",
    "plt.xlabel(\"Action\")\n",
    "plt.ylabel(\"Reward distribution\")\n",
    "plt.savefig(\"../generated_images/figure_2_1.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:07:18.925314Z",
     "start_time": "2025-03-01T18:07:18.793703Z"
    }
   },
   "id": "8ed1daafa4064440",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Greedy Action Selection VS Œµ-greedy Action Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef67eb7574c5d2b1"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Create a list of epsilons with 0, 0.1 and 0.01 values\n",
    "epsilons = [0, 0.1, 0.01]\n",
    "\n",
    "# Create a list of bandits (1 bandit for every epsilon) where every bandit uses sample-average method\n",
    "bandits = [Bandit(epsilon=e, use_gradient=True) for e in epsilons]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T19:35:01.392072Z",
     "start_time": "2025-03-02T19:35:01.387556Z"
    }
   },
   "id": "6a180bc790c31e65",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define number of runs\n",
    "runs = 2000\n",
    "\n",
    "# Define number of times\n",
    "time = 1000\n",
    "\n",
    "# Simulate optimal action counts and rewards\n",
    "optimal_action_counts, rewards = simulate(runs, time, bandits)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "683805477a8d4606"
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T18:07:30.092753Z",
     "start_time": "2025-03-01T18:07:30.077161Z"
    }
   },
   "id": "e1a86ca5f4aefa2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x2000 with 0 Axes>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "for epsilon, rewards in zip(epsilons, rewards):\n",
    "    plt.plot(rewards, label=\"$\\epsilon = %.02f$\" % epsilon)\n",
    "plt.title(\"Figure 2.2\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T22:49:21.555505Z",
     "start_time": "2025-03-02T22:49:21.517829Z"
    }
   },
   "id": "5536109f4e591e72",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid escape sequence '\\e'\n",
      "invalid escape sequence '\\e'\n",
      "invalid escape sequence '\\e'\n",
      "invalid escape sequence '\\e'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m plt\u001B[38;5;241m.\u001B[39msubplot(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epsilon, rewards \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(epsilons, \u001B[43mrewards\u001B[49m):\n\u001B[0;32m      3\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(rewards, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mepsilon = \u001B[39m\u001B[38;5;132;01m%.02f\u001B[39;00m\u001B[38;5;124m$\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m epsilon)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFigure 2.2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'rewards' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 2)\n",
    "for epsilon, counts in zip(epsilons, optimal_action_counts):\n",
    "    plt.plot(counts, label=\"$\\epsilon = %.02f$\" % epsilon)\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"% Optimal action\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e6157d53f01223f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.savefig(\"../generated_images/figure_2_2.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca9dfed4b31f4579"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Optimistic Initial Values VS Realistic Initial Values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0c5945f58dd0dee"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 2 bandits where:\n",
    "# 1. 1st bandit: Œµ = 0, ùëÑ_1(ùëé) = 5, ùõº = 0.1,\n",
    "# 2. 2nd bandit: Œµ = 0.1, ùëÑ_1(ùëé) = 0, ùõº = 0.1\n",
    "\n",
    "bandits = [Bandit(epsilon=0, initial_action_value_estimates=5, step_size=0.1),\n",
    "           Bandit(epsilon=0.1, initial_action_value_estimates=0, step_size=0.1)]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T07:55:29.820855Z",
     "start_time": "2025-03-03T07:55:29.814833Z"
    }
   },
   "id": "50d647979ced258a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandic class constructor print\n",
      "Bandic class test print\n",
      "Bandic class constructor print\n",
      "Bandic class test print\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "runs = 2000\n",
    "\n",
    "# Define number of times\n",
    "times = 1000\n",
    "\n",
    "# Simulate optimal action counts\n",
    "optimal_action_counts, _ = simulate(runs, times, bandits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T07:57:14.922032Z",
     "start_time": "2025-03-03T07:56:00.677328Z"
    }
   },
   "id": "3116e78a4c90c435",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:37<00:00, 52.88it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:36<00:00, 54.98it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "plt.plot(optimal_action_counts[0], label=\"$\\epsilon = 0, Q1 = 5$\")\n",
    "plt.plot(optimal_action_counts[1], label=\"$\\epsilon = 0.1, Q1 = 0$\")\n",
    "plt.title(\"Figure 2.3\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"% Optimal action\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../generated_images/figure_2_3.png\")\n",
    "plt.close()\n",
    "# plt.figure(figsize=(10, 20))\n",
    "# plt.subplot(2, 1, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:09:36.150496Z",
     "start_time": "2025-03-03T08:09:35.966315Z"
    }
   },
   "id": "d1ae633f8632eed5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_9700\\277590725.py:2: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  plt.plot(optimal_action_counts[0], label=\"$\\epsilon = 0, Q1 = 5$\")\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_9700\\277590725.py:3: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  plt.plot(optimal_action_counts[1], label=\"$\\epsilon = 0.1, Q1 = 0$\")\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Upper-Confidence-Bound (UCB) Action Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7473708c239f1d0"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 2 bandits where:\n",
    "# 1. 1st bandit: Œµ = 0, ùëê = 2, uses sample-average method,\n",
    "# 2. 2nd bandit: Œµ = 0.1, uses sample-average method\n",
    "bandits = [Bandit(epsilon=0, confidence_level=2, use_gradient=True),\n",
    "           Bandit(epsilon=0.1, use_gradient=True)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T09:35:56.115242Z",
     "start_time": "2025-03-10T09:35:56.107037Z"
    }
   },
   "id": "1993531b4fe5feb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandic class constructor print\n",
      "Bandic class test print\n",
      "Bandic class constructor print\n",
      "Bandic class test print\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "runs = 2000\n",
    "\n",
    "# Define number of times\n",
    "times = 1000\n",
    "\n",
    "# Simulate average rewards\n",
    "_, average_rewards = simulate(runs, times, bandits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T09:37:30.502064Z",
     "start_time": "2025-03-10T09:36:04.590800Z"
    }
   },
   "id": "6e1fed28f6812c2e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:47<00:00, 42.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:38<00:00, 52.05it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "plt.plot(average_rewards[0], label=\"UCB $c = 2$\")\n",
    "plt.plot(average_rewards[1], label=\"epsilon-greedy $\\epsilon = 0.1$\")\n",
    "\n",
    "plt.title(\"Figure 2.4\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../generated_images/figure_2_4.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T11:25:55.389375Z",
     "start_time": "2025-03-10T11:25:55.327623Z"
    }
   },
   "id": "9d4db60f0153c024",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_15672\\2580699317.py:5: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  plt.plot(average_rewards[1], label=\"epsilon-greedy $\\epsilon = 0.1$\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Plotting\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmatplotlib\u001B[49m\u001B[38;5;241m.\u001B[39muse(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAgg\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(average_rewards[\u001B[38;5;241m0\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUCB $c = 2$\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(average_rewards[\u001B[38;5;241m1\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepsilon-greedy $\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mepsilon = 0.1$\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Gradient Bandit Algorithms (GBA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5cb31b7d224bbba"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 4 bandits where:\n",
    "# 1. 1st bandit: uses GBA, ùõº = 0.1, uses average reward as baseline for GBA, expects true reward of 4,\n",
    "# 2. 2nd bandit: uses GBA, ùõº = 0.1, doesn't use average reward as baseline for GBA, expects true reward of 4,\n",
    "# 3. 3rd bandit: uses GBA, ùõº = 0.4, uses average reward as baseline for GBA, expects true reward of 4,\n",
    "# 4. 4th bandit: uses GBA, ùõº = 0.4, doesn't use average reward as baseline for GBA, expects true reward of 4\n",
    "\n",
    "bandits = [\n",
    "    Bandit(use_gradient=True, step_size=0.1, use_gradient_baseline=True, true_expected_reward=4),\n",
    "    Bandit(use_gradient=True, step_size=0.1, use_gradient_baseline=False, true_expected_reward=4),\n",
    "    Bandit(use_gradient=True, step_size=0.4, use_gradient_baseline=True, true_expected_reward=4),\n",
    "    Bandit(use_gradient=True, step_size=0.4, use_gradient_baseline=False, true_expected_reward=4),\n",
    "\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T10:07:52.639630Z",
     "start_time": "2025-03-10T10:07:52.625488Z"
    }
   },
   "id": "1453e8fb0e6a32f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandic class constructor print\n",
      "Bandic class test print\n",
      "Bandic class constructor print\n",
      "Bandic class test print\n",
      "Bandic class constructor print\n",
      "Bandic class test print\n",
      "Bandic class constructor print\n",
      "Bandic class test print\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "runs = 2000\n",
    "\n",
    "# Define number of times\n",
    "times = 1000\n",
    "\n",
    "# Simulate optimal action counts\\\n",
    "optimal_action_counts, _ = simulate(runs, times, bandits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T10:10:27.703741Z",
     "start_time": "2025-03-10T10:10:25.290384Z"
    }
   },
   "id": "79a2acb7e523f0a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñé         | 71/2000 [00:02<01:04, 29.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m times \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Simulate optimal action counts\\\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m optimal_action_counts, _ \u001B[38;5;241m=\u001B[39m \u001B[43msimulate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mruns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbandits\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[16], line 32\u001B[0m, in \u001B[0;36msimulate\u001B[1;34m(runs, times, bandits)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# for every time step\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m time \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(times):\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;66;03m# select an action\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[43mbandit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mact\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;66;03m# get the reward\u001B[39;00m\n\u001B[0;32m     35\u001B[0m     rewards[i, run, time] \u001B[38;5;241m=\u001B[39m bandit\u001B[38;5;241m.\u001B[39mstep(action)\n",
      "File \u001B[1;32m~\\Desktop\\ReinforcementLearning\\ten-armed-testbed\\src\\bandit.py:146\u001B[0m, in \u001B[0;36mBandit.act\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;66;03m# endregion Summary\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \n\u001B[0;32m    140\u001B[0m \u001B[38;5;66;03m# region Body\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    143\u001B[0m \n\u001B[0;32m    144\u001B[0m \u001B[38;5;66;03m# Œµ-greedy action selection: every once in a while, with small probability Œµ, select randomly from among all the actions with equal probability, independently of the action-value estimates.\u001B[39;00m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandn() \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepsilon:\n\u001B[1;32m--> 146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;66;03m# endregion Œµ-greedy\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \n\u001B[0;32m    150\u001B[0m \u001B[38;5;66;03m# region UCB\u001B[39;00m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfidence_level \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Labels\n",
    "labels  =[\n",
    "    r\"$\\alpha = 0.1$ with baseline\",\n",
    "    r\"$\\alpha = 0.1$ without baseline\",\n",
    "    r\"$\\alpha = 0.4$ with baseline\",\n",
    "    r\"$\\alpha = 0.4$ without baseline\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T10:05:47.629855Z",
     "start_time": "2025-03-10T10:05:47.618308Z"
    }
   },
   "id": "67282242fae58cb9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "for i in range(len(bandits)):\n",
    "    plt.plot(optimal_action_counts[i], label=labels[i])\n",
    "\n",
    "plt.title(\"Figure 2.5\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"% Optimal action\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../generated_images/figure_2.5.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T10:05:52.911278Z",
     "start_time": "2025-03-10T10:05:52.750631Z"
    }
   },
   "id": "2281e1a4dc8f1b9c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "974417449ca9770c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
